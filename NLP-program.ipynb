{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lọc và lưu vào file du_lieu.json\n"
     ]
    }
   ],
   "source": [
    "# code để lọc cột name khỏi file dữ liệu gốc\n",
    "import json\n",
    "import pandas as pd\n",
    "# Đọc dữ liệu từ file JSON gốc\n",
    "input_file = 'du_lieu_goc.json' # đây là file của kiệt ban đầu gửi đã đc đổi tên\n",
    "output_file = 'du_lieu.json'# sau khi mà lọc bỏ cột name không cần thiết dữ liệu sẽ đc đưa vào đây\n",
    "# Đọc file JSON\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "# Chuyển đổi dữ liệu thành DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Xóa cột \"Name\"\n",
    "if 'Name (click to view profile)' in df.columns:\n",
    "    df = df.drop(columns=['Name (click to view profile)'])\n",
    "# Ghi dữ liệu đã lọc vào file JSON mới\n",
    "df.to_json(output_file, orient='records', force_ascii=False, indent=4)\n",
    "print(f\"Dữ liệu đã được lọc và lưu vào file {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được ghi vào tien_xu_li_1.json\n"
     ]
    }
   ],
   "source": [
    "# Tiền xử lí một gôm các bước lọc emoji, loại bỏ stopwords và các kí tự đặc biệt và kiểm tra xem dữ liệu có bị trống tại chỉ mục comment hoặc label không\n",
    "import json\n",
    "import re\n",
    "# Đọc file JSON\n",
    "file_path = 'du_lieu.json'  # file cần xử lí là file mà sau khi đã lọc cột name\n",
    "output_file_path = 'tien_xu_li_1.json'  # Đường dẫn tới file JSON đầu ra sau khi xử lí sẽ lưu vào đây\n",
    "# Danh sách stopwords ( m mà muốn thêm hoặc bớt thì có thể tự thêm )\n",
    "stopwords = set([\n",
    "    'và', 'của', 'là', 'theo', 'để', 'trong', 'đã', 'một', 'này', 'cái', 'lại', 'có', 'khi', 'vì', 'chúng', 'tôi', 'bạn', 'sẽ', 'nhưng', 'với', 'mình', 'cùng'\n",
    "])\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # Flags (Regional Indicator Symbols)\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", text)\n",
    "def clean_text(text):\n",
    "    # Loại bỏ emoji\n",
    "    text = remove_emoji(text)\n",
    "    # Loại bỏ ký tự đặc biệt, giữ lại chữ và khoảng trắng\n",
    "    text = re.sub(r'[^\\w\\sáàạảãạăắằặẳẵâấầậẩẫéèẹẻẽêếềệểễíìịỉĩóòọỏõôốồộổỗơớờợởỡúùụủũưứừựửữýỳýỵỷỹđ]', '', text)\n",
    "    # Chuyển tất cả chữ về dạng viết thường\n",
    "    text = text.lower()\n",
    "    # Loại bỏ stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    return text\n",
    "# Đọc dữ liệu từ file JSON\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "# Lọc và xử lý các mục comment, kiểm tra label và chỉ ghi lại những phần hợp lệ\n",
    "processed_data = []\n",
    "for item in data:\n",
    "    comment = item.get('Comment', None)\n",
    "    label = item.get('Label', None)\n",
    "    # Kiểm tra xem cả comment và label có bị null không\n",
    "    if comment and label:\n",
    "        # Xử lý comment nếu có\n",
    "        item['Comment'] = clean_text(comment)\n",
    "        processed_data.append(item)\n",
    "    else:\n",
    "        if comment is None:\n",
    "            print(f\"Comment null tại chỉ mục {data.index(item)}\")\n",
    "        if label is None:\n",
    "            print(f\"Label null tại chỉ mục {data.index(item)}\")\n",
    "# Ghi lại dữ liệu đã xử lý vào file JSON mới\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "print(f\"Dữ liệu đã được ghi vào {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "positive    452\n",
      "negative    376\n",
      "neutral     189\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#đếm dữ liệu từng nhãn\n",
    "import json\n",
    "import pandas as pd\n",
    "# Đọc dữ liệu từ file JSON\n",
    "with open('tien_xu_li_1.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "# Chuyển thành DataFrame để dễ xử lý\n",
    "df = pd.DataFrame(data)\n",
    "# Hiển thị thông tin cơ bản\n",
    "print(df['Label'].value_counts())  # Đếm số lượng từng nhãn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
